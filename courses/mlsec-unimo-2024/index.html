<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Short Ph.D. Course at UniMo (2024) | Fabio Pierazzi</title> <meta name="author" content="Fabio Pierazzi"> <meta name="description" content="Personal Web page of Fabio Pierazzi. "> <meta name="keywords" content="fabio, pierazzi, systems, security"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://fabio.pierazzi.com/courses/mlsec-unimo-2024/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Fabio </span>Pierazzi</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/team/">team</a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service</a> </li> <li class="nav-item "> <a class="nav-link" href="/opportunities/">opportunities</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Short Ph.D. Course at UniMo (2024)</h1> <p class="post-description"></p> </header> <article> <p>October 4th, 2024<br> Duration: 4 hours</p> <h3 id="security-of-machine-learning-in-hostile-environments">Security of Machine Learning in Hostile Environments</h3> <p>Machine Learning (ML) has shown incredible success in many applications, including computer vision, and speech recognition. However, the use of ML can increase also the attack surface, and paves the way for attackers to compromise confidentiality, integrity or availability of ML systems. This is especially relevant in hostile environments such as cybersecurity, where the attacker wants to evade detection and wants the ML system to malfunction.</p> <p>This brief course will provide you with an overview of the challenges and trends in assessing risks and robustness of applying machine learning, i.e., contexts that consider the presence of a hostile adversary, and that require modifications of complex objects (e.g., software). We will refer to malware detection as a main case study, but this applies to any hostile environment where adversaries could gain some benefit.</p> <p>A brief outline of the topics is as follows:</p> <ul> <li>Introduction to Machine Learning in Hostile Environments, including Cybersecurity</li> <li>Taxonomy of adversarial attacks</li> <li>Attacks on XAI methods</li> <li>Security of foundation models (Generative AI, Diffusion Models, LLMs)</li> <li>Defense directions</li> </ul> <h3 id="required-skills">Required skills</h3> <p>Required:</p> <ul> <li>Computer Science background</li> <li>Software engineering basics</li> <li>Networking basics</li> <li>Machine Learning basics</li> </ul> <p>Preferred (but not required):</p> <ul> <li>Cybersecurity</li> </ul> <h3 id="timetable">Timetable</h3> <table> <thead> <tr> <th>Date</th> <th>Time    </th> <th>Location</th> </tr> </thead> <tbody> <tr> <td>Friday, October 4th, 2024</td> <td>9-13</td> <td>Aula M2.4 - Matematica</td> </tr> </tbody> </table> <p><br></p> <h3 id="assessment-optional">Assessment (Optional)</h3> <p>This course offers an optional exam, for students who opt-in to do it (e.g., for getting credits in their Ph.D. programme).</p> <p>The assessment requires to write an extended abstract (min 1000-max 1500 chars, spaces included) that summarizes how your research relates to (and can be improved) by one paper of your choice from the References list below. The abstract should contain:</p> <ol> <li>Statement of a problem in your own research that is related to your chosen paper</li> <li>Idea for a possible novel solution that integrates the chosen paper and your research</li> <li>Novelty with respect to the state of the art</li> </ol> <p>Submit your extended abstract <strong>by October 25th, 2024</strong> via this form: <a href="https://forms.gle/Ga2sgRyZEmiK6sWh6" rel="external nofollow noopener" target="_blank">click here</a></p> <p>You can download course material <a href="https://emckclac-my.sharepoint.com/:b:/g/personal/k1802448_kcl_ac_uk/Ed1YVvl8oqRAsyoEKrYYUXMBBYV8SH5B_bAdcVZMXcrJHA?e=V1CM5k" rel="external nofollow noopener" target="_blank">from here</a> (until Oct 11th, 2024).</p> <p>Assessment criteria:</p> <ul> <li>Demonstrating understanding of the chosen paper content and topic</li> <li>Ability to position your own research within the context of robust machine learning and security</li> <li>Clarity of presentation</li> <li>Correct use of technical terms seen in this short course</li> <li>Quality of the idea proposed</li> </ul> <p>You will also receive a personalized feedback on your abstract.</p> <h3 id="lecturer-biography">Lecturer Biography</h3> <p>Dr. Fabio Pierazzi is a Senior Lecturer (Associate Professor) in Computer Science and Deputy Head of the Cybersecurity group at the Department of Informatics of King’s College London, and affiliated with UCL’s Systems Security Research Lab (S2Lab). His research interests are at the intersection of systems security and machine learning, with a particular emphasis on settings in which attackers adapt quickly to new defenses (i.e., high non-stationarity, adaptive attackers). Previously, he obtained his Ph.D. in Computer Science at University of Modena, Italy (2014–2017), he visited University of Maryland, College Park, USA (2016), and he was a Post-Doctoral Research Associate at Royal Holloway, University of London (2017–2019). Home page: <a href="https://fabio.pierazzi.com">https://fabio.pierazzi.com</a></p> <h3 id="references">References</h3> <p>See <a href="../../blog/2021/literature-review-systems-security/">advice on reviewing literature for systems security</a>.</p> <p>Best Practices for MLSec</p> <ul> <li>Arp et al., “<a href="dodo-mlsec.org">Dos and Don’ts of Machine Learning in Computer Security</a>”, USENIX Security Symposium, 2022 (Distinguished Paper Award)</li> </ul> <p>Adversarial ML: Evasion</p> <ul> <li>Carlini and Wagner, <a href="https://arxiv.org/abs/1608.04644" rel="external nofollow noopener" target="_blank">Towards Evaluating the Robustness of Neural Networks</a>, IEEE Symposium on Security &amp; Privacy, 2016 (Best Paper Award)</li> <li>Pierazzi et al., “<a href="https://fabio.pierazzi.com/papers/pierazzi_intriguing.pdf">Intriguing Properties of Adversarial ML Attacks in the Problem Space</a>”, IEEE Symposium on Security &amp; Privacy, 2022</li> <li>Athalye et al. “<a href="https://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf" rel="external nofollow noopener" target="_blank">Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples</a>”, ICML, 2018.</li> <li>Quiring et al., “<a href="https://www.usenix.org/system/files/sec19-quiring.pdf" rel="external nofollow noopener" target="_blank">Misleading Authorship Attribution of Source Code using Adversarial Learning</a>”, USENIX Security Symposium, 2019</li> </ul> <p>Adversarial ML: Backdoor</p> <ul> <li>Yang et al., “<a href="https://kclpure.kcl.ac.uk/portal/files/204793925/IEEESP23_Jigsaw_Puzzle.pdf" rel="external nofollow noopener" target="_blank">Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers</a>”, IEEE Symposium on Security &amp; Privacy, 2023</li> </ul> <p>Adversarial ML: Poisoning</p> <ul> <li>Shan et al., “<a href="https://www.usenix.org/conference/usenixsecurity22/presentation/shan" rel="external nofollow noopener" target="_blank">Poison forensics: Traceback of data poisoning attacks in neural networks</a>.” USENIX Security Symposium, 2022</li> </ul> <p>Adversarial ML: General and Defenses</p> <ul> <li>Tramer et al., <a href="https://arxiv.org/abs/2002.08347" rel="external nofollow noopener" target="_blank">On Adaptive Attacks to Adversarial Example Defenses</a>, NeurIPS, 2020</li> <li>Biggio and Roli, <a href="https://arxiv.org/abs/1712.03141" rel="external nofollow noopener" target="_blank">Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning</a>, Pattern Recognition, 2018</li> <li>De Cristofaro, <a href="https://emilianodc.com/PAPERS/IEEESP2021.pdf" rel="external nofollow noopener" target="_blank">A Critical Overview of Privacy in Machine Learning</a>, IEEE Security &amp; Privacy Magazine, 2021</li> <li>Papers cited by Nicholas Carlini in his <a href="https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html" rel="external nofollow noopener" target="_blank">Adversarial ML Reading List</a> </li> <li>Demontis et al., “<a href="https://arxiv.org/abs/1704.08996" rel="external nofollow noopener" target="_blank">Yes, machine learning can be more secure! A case study on android malware detection</a>“ IEEE Transactions on Dependable and Secure Computing (TDSC), 2017</li> </ul> <p>Socio-technical MLSec</p> <ul> <li>Aonzo et al., “<a href="https://www.usenix.org/system/files/sec23summer_241-aonzo-prepub.pdf" rel="external nofollow noopener" target="_blank">Humans vs. Machine in Malware Classification</a>”, USENIX Security Symposium, 2023</li> </ul> <p>Malware Detection</p> <ul> <li>Arp et al., <a href="https://mlsec.org/docs/2014-ndss.pdf" rel="external nofollow noopener" target="_blank">Drebin: Effective and explainable detection of android malware in your pocket.</a>, NDSS, 2014</li> </ul> <p><br></p> </article> </div> </div> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Fabio Pierazzi. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 30, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-3D290BNS4E"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-3D290BNS4E");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>